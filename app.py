import streamlit as st
import pandas as pd
import numpy as np
from PIL import Image
import requests
import json
import pickle
from datetime import datetime
import os
import sys
import logging

# Configure error handling and logging
logging.basicConfig(level=logging.INFO, 
                   format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Import functions from location_api.py
try:
    from location_api import (
        get_coordinates,
        find_collection_points,
        fetch_collection_dates,
        get_next_collection_date,
        format_collection_points,
        get_available_waste_types,
        translate_waste_type,
        fetch_collection_points,
        COLLECTION_POINTS_ENDPOINT,
        COLLECTION_DATES_ENDPOINT,
        handle_waste_disposal,
        create_interactive_map
    )
    logger.info(f"Successfully imported location_api functions")
    logger.info(f"Collection Points API: {COLLECTION_POINTS_ENDPOINT}")
    logger.info(f"Collection Dates API: {COLLECTION_DATES_ENDPOINT}")
except ImportError as e:
    st.error(f"Failed to import from location_api.py: {str(e)}")
    logger.error(f"Import error: {str(e)}")
    st.stop() # Stop execution if the core dependency is missing
except Exception as e:
    st.error(f"An unexpected error occurred while importing location_api.py: {str(e)}")
    logger.error(f"Unexpected error: {str(e)}")
    st.stop() # Stop execution on other import errors

# Initialize session state if not already done
if 'waste_info_results' not in st.session_state:
    st.session_state.waste_info_results = None
    st.session_state.show_results = False

# Function to check if ML models are available (moved to app.py to be accessible by all pages)
def check_ml_models_available():
    """Check if ML model files exist"""
    required_files = ['waste_classifier.pkl', 'waste_vectorizer.pkl', 'waste_encoder.pkl']
    
    for file in required_files:
        if not os.path.exists(file):
            return False
    return True

# Function to check if TensorFlow is available
def check_tensorflow_available():
    """Check if TensorFlow is available"""
    try:
        import tensorflow
        return True
    except ImportError:
        return False

# Function to load the text model - fixed version
@st.cache_resource
def load_text_model():
    """Load text classification model with proper error handling"""
    try:
        if not check_ml_models_available():
            logger.warning("ML model files not found")
            return None, None, None
            
        with open('waste_classifier.pkl', 'rb') as f:
            model = pickle.load(f)
        with open('waste_vectorizer.pkl', 'rb') as f:
            vectorizer = pickle.load(f)
        with open('waste_encoder.pkl', 'rb') as f:
            encoder = pickle.load(f)
        return model, vectorizer, encoder
    except Exception as e:
        logger.error(f"Error loading text model: {str(e)}")
        return None, None, None

# Function to load the image model
@st.cache_resource
def load_image_model():
    """Load image classification model with proper error handling"""
    try:
        if not check_tensorflow_available():
            logger.warning("TensorFlow not available")
            return None
            
        if not os.path.exists("waste_image_classifier.h5"):
            logger.warning("Image model file not found")
            return None
            
        from tensorflow.keras.models import load_model
        return load_model("waste_image_classifier.h5")
    except Exception as e:
        logger.error(f"Error loading image model: {str(e)}")
        return None

# Rules-based fallback prediction when ML models aren't available
def rule_based_prediction(description):
    """Rule-based prediction for when ML models aren't available"""
    description = description.lower()
    
    # Keywords for each category
    keywords = {
        "Household waste üóë": ["trash", "garbage", "waste", "dirty", "leftover", "broken", "ordinary"],
        "Paper üìÑ": ["paper", "newspaper", "magazine", "book", "printer", "envelope", "document"],
        "Cardboard üì¶": ["cardboard", "carton", "box", "packaging", "thick paper"],
        "Glass üçæ": ["glass", "bottle", "jar", "container", "mirror", "window"],
        "Green waste üåø": ["green", "grass", "leaf", "leaves", "plant", "garden", "flower", "vegetable", "fruit"],
        "Cans ü•´": ["can", "tin", "aluminum can", "soda", "drink can", "food can"],
        "Aluminium üß¥": ["aluminum", "foil", "tray", "container", "lid", "wrap", "packaging"],
        "Metal ü™ô": ["metal", "iron", "steel", "scrap", "nails", "screws", "wire"],
        "Textiles üëï": ["textile", "clothes", "fabric", "shirt", "pants", "cloth", "cotton", "wool"],
        "Oil üõ¢": ["oil", "cooking oil", "motor oil", "lubricant", "grease"],
        "Hazardous waste ‚ö†": ["battery", "chemical", "toxic", "medicine", "paint", "solvent", "cleaner"],
        "Foam packaging ‚òÅ": ["foam", "styrofoam", "polystyrene", "packing", "cushion", "insulation"]
    }
    
    # Score each category
    scores = {}
    for category, word_list in keywords.items():
        scores[category] = 0
        for word in word_list:
            if word in description:
                scores[category] += 1
    
    # Find best category
    if any(scores.values()):
        best_category = max(scores, key=scores.get)
        confidence = min(0.7, scores[best_category] / len(keywords[best_category]))
        return best_category, confidence
    else:
        return "Household waste üóë", 0.3  # Default category

# Simple image-based prediction as fallback
def simple_image_prediction(image):
    """Simple color-based prediction as fallback for image classification"""
    try:
        # Convert to numpy array
        img_array = np.array(image)
        
        # Analyze average color
        avg_color = np.mean(img_array, axis=(0, 1))
        
        # Simple logic based on dominant color
        r, g, b = avg_color[:3]
        
        if g > r and g > b:  # Green dominant
            return "Green waste üåø", 0.5
        elif b > r and b > g:  # Blue dominant
            return "Paper üìÑ", 0.4
        elif r > g and r > b:  # Red/Brown dominant
            return "Cardboard üì¶", 0.4
        elif r > 200 and g > 200 and b > 200:  # Very light
            return "Foam packaging ‚òÅ", 0.4
        elif r < 50 and g < 50 and b < 50:  # Very dark
            return "Metal ü™ô", 0.4
        else:
            return "Household waste üóë", 0.3
    except Exception as e:
        logger.error(f"Error in color-based prediction: {str(e)}")
        return "Household waste üóë", 0.3

# Enhanced predict_from_text function with fallback
def predict_from_text(description, model=None, vectorizer=None, encoder=None):
    """Predict waste type from text with fallback to rule-based"""
    if not description:
        return None, 0.0
    
    # Use ML model if available
    if model is not None and vectorizer is not None and encoder is not None:
        try:
            description = description.lower()
            X_new = vectorizer.transform([description])
            prediction = model.predict(X_new)[0]
            probabilities = model.predict_proba(X_new)[0]
            confidence = probabilities[prediction]
            
            # Get category from encoder and ensure it's in the right format
            category = encoder.inverse_transform([prediction])[0]

        # Map category to UI format with emojis if needed
            category_mapping = {
                "Household": "Household waste üóë",
                "Paper": "Paper üìÑ",
                "Cardboard": "Cardboard üì¶",
                "Glass": "Glass üçæ",
                 "Green": "Green waste üåø",
                "Cans": "Cans ü•´",
                "Aluminium": "Aluminium üß¥",
                "Metal": "Metal ü™ô",
                "Textiles": "Textiles üëï",
                "Oil": "Oil üõ¢",
                "Hazardous": "Hazardous waste ‚ö†",
                "Foam packaging": "Foam packaging ‚òÅ"
            }

            ui_category = category_mapping.get(category, category)

            if confidence < 0.3:
                return "Unknown üö´", float(confidence)

            return ui_category, float(confidence)

        except Exception as e:
            logger.error(f"Error in ML text prediction: {str(e)}")
            # Fall back to rule-based
            return rule_based_prediction(description)
    else:
        # Fall back to rule-based prediction
        logger.info("ML model not available, using rule-based prediction")
        return rule_based_prediction(description)

# Enhanced predict_from_image function with fallback
def predict_from_image(img, model=None, class_names=None):
    """Predict waste type from image with fallback to color-based"""
    if model is None or class_names is None:
        # Fallback to color-based prediction
        logger.info("Image model not available, using color-based prediction")
        return simple_image_prediction(img)
        
    try:
        # Ensure TensorFlow is imported
        import tensorflow as tf
        from tensorflow.keras.preprocessing import image as keras_image
        
        # Preprocess image
        img = img.resize((224, 224))
        img_array = keras_image.img_to_array(img)
        img_array = np.expand_dims(img_array, axis=0)
        img_array = img_array / 255.0
        
        # Make prediction
        predictions = model.predict(img_array)
        class_idx = np.argmax(predictions[0])
        confidence = float(np.max(predictions[0]))
        
        # Get class name
        if class_idx < len(class_names):
            category = class_names[class_idx]
            return category, confidence
        else:
            logger.error(f"Invalid class index: {class_idx}, max expected: {len(class_names)-1}")
            return simple_image_prediction(img)
            
    except Exception as e:
        logger.error(f"Error in image prediction: {str(e)}")
        return simple_image_prediction(img)

# Function to convert waste type selected in UI to API format
def convert_waste_type_to_api(ui_waste_type):
    mapping = {
        "Household waste üóë": "Kehricht",
        "Paper üìÑ": "Papier",
        "Cardboard üì¶": "Karton",
        "Glass üçæ": "Glas",
        "Green waste üåø": "Gr√ºngut",
        "Cans ü•´": "Dosen",
        "Aluminium üß¥": "Aluminium",
        "Metal ü™ô": "Altmetall",
        "Textiles üëï": "Alttextilien",
        "Oil üõ¢": "Alt√∂l",
        "Hazardous waste ‚ö†": "Sonderabfall",
        "Foam packaging ‚òÅ": "Styropor"
    }
    return mapping.get(ui_waste_type, ui_waste_type)

# Convert API waste type to UI format (with emojis)
def convert_api_to_ui_waste_type(api_waste_type):
    mapping = {
        "Kehricht": "Household waste üóë",
        "Papier": "Paper üìÑ",
        "Karton": "Cardboard üì¶",
        "Glas": "Glass üçæ",
        "Gr√ºngut": "Green waste üåø",
        "Dosen": "Cans ü•´",
        "Aluminium": "Aluminium üß¥",
        "Altmetall": "Metal ü™ô",
        "Alttextilien": "Textiles üëï",
        "Alt√∂l": "Oil üõ¢",
        "Sonderabfall": "Hazardous waste ‚ö†",
        "Styropor": "Foam packaging ‚òÅ"
    }
    return mapping.get(api_waste_type, api_waste_type)

# Define image class names (needed across pages)
IMAGE_CLASS_NAMES = [
    "Household waste üóë", 
    "Paper üìÑ", 
    "Cardboard üì¶", 
    "Glass üçæ", 
    "Green waste üåø", 
    "Cans ü•´", 
    "Aluminium üß¥", 
    "Foam packaging ‚òÅ", 
    "Metal ü™ô", 
    "Textiles üëï", 
    "Oil üõ¢", 
    "Hazardous waste ‚ö†"
]

# Try importing folium and streamlit_folium upfront
try:
    import folium
    from streamlit_folium import st_folium
    logger.info("Successfully imported folium and streamlit_folium")
except ImportError as e:
    logger.warning(f"Failed to import map libraries: {str(e)}")
    logger.warning("Maps functionality might be limited")

# Redirect to the Home page
import streamlit.web.bootstrap
from streamlit.web.server.server import Server
import os

if __name__ == "__main__":
    # Set page config for the main app (needed even though we redirect)
    st.set_page_config(
        page_title="WasteWise - Your smart recycling assistant",
        page_icon="‚ôªÔ∏è",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    # Hide ALL built-in Streamlit navigation elements - PUT THE CSS HERE
    hide_streamlit_style = """
    <style>
    /* Hide the default sidebar navigation */
    [data-testid="stSidebarNavItems"] {
        display: none !important;
    }

    /* Hide the expand/collapse arrow */
    button[kind="header"] {
        display: none !important;
    }

    /* Remove the extra padding at the top of sidebar */
    section[data-testid="stSidebar"] > div {
        padding-top: 1rem !important;
    }

    /* Optional: Hide app name from sidebar header if present */
    .sidebar-content .sidebar-collapse-control {
        display: none !important;
    }
    </style>
    """
    st.markdown(hide_streamlit_style, unsafe_allow_html=True)
    
    # Create a simple loading page
    st.write("# Loading WasteWise...")
    st.write("Please wait while we load the application...")
    
    # Redirect to the Home page
    st.switch_page("1_Home.py")